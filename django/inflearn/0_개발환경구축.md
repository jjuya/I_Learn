# 웹 크롤링을 이용한 서비스 개발

### 0. 개발환경 구축

##### 1) 가상환경 웹 서버(Vagrant)

###### Vagrantfile 생성

```
vagrant init ubuntu xenial
```



###### vagrant 설정

- 먼저 호스트머신으로 접속한 port(8080)를 가상머신의 port(80)로 전달

  ```
    config.vm.network "forwarded_port", guest: 80, host: 8080
  ```

  ​

- 가상머신의 아이피주소를 설정

  ```
    config.vm.network "private_network", ip: "192.168.33.10"
  ```



##### 2) Python 2.X

- 가상 환경 서버 접속 후



###### upbuntu setting

```bash
# 패키지 매니저 update
sudo apt-get update

# 개발에 필요한 기본적인 패키지
sudo apt-get install build-essential
```



###### Python 버전 확인

```bash
python -V

# 안깔려 있다면
sudo apt install python
```



###### pip( Python 패키지 매니저) 설치

```bash
sudo apt-get install python-pip
```



##### 3) Python 가상환경 구축

###### virtualenv 설치

- 서버에서는 필요한 패키지만 올리기 위해 **캡슐화**
- 이 가상환경에서만 파이선이 작동하도록

```bash
sudo pip install virtualenv virtualenvwrapper
```



###### virtualenv 설정

```bash
vi .bashrc
```

```bash
# 맨 밑에 추가
export WORKON_HOME=$HOME/.virtualenvs
source /usr/local/bin/virtualenvwrapper.sh
```

```bash
source .bashrc
```



###### virtualenv 생성

```bash
ubuntu@ubuntu-xenial:/vagrant$ mkvirtualenv myenv
New python executable in /home/ubuntu/.virtualenvs/myenv/bin/python
Installing setuptools, pip, wheel...done.
virtualenvwrapper.user_scripts creating /home/ubuntu/.virtualenvs/myenv/bin/predeactivate
virtualenvwrapper.user_scripts creating /home/ubuntu/.virtualenvs/myenv/bin/postdeactivate
virtualenvwrapper.user_scripts creating /home/ubuntu/.virtualenvs/myenv/bin/preactivate
virtualenvwrapper.user_scripts creating /home/ubuntu/.virtualenvs/myenv/bin/postactivate
virtualenvwrapper.user_scripts creating /home/ubuntu/.virtualenvs/myenv/bin/get_env_details
(myenv) ubuntu@ubuntu-xenial:/vagrant$
```

- .bashrc에 입력한 디렉토리에 가상환경 생성
- `deactivate` : 가상환경 종료
- `workon myenv` : 가상환경 접속



##### 4) beautifulsoup

- virtualenv 접속 후

###### lxml defendency 설치 

```bash
sudo apt-get install libxml2-dev libxslt-dev python-dev zlib1g-dev
sudo apt-get install python-lxml
pip install lxml
```



###### beautifulsoup 설치 

```bash
pip install beautifulsoup4
```



##### 5) Scrapy

###### defendency 설치

```bash
sudo apt-get install libffi-dev libssl-dev
```



###### Scrapy 설치

```bash
pip install Scrapy
```

