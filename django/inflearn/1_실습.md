# 웹 크롤링을 이용한 서비스 개발

### 1. Scrapy 실습

- ubuntu 가상머신의 python 가상환경에서 진행

```bash
workon myenv
```



##### 1) Scrapy project 생성

```bash
scrapy startproject tutorial
```



##### 2) Scrapy 구조 

![scrapyproject](scrapyproject.png)



###### items.py

데이터를 들고 올 때, 그 데이터를 클래스로 만들 수 있다.



###### pipelines.py

가져온 데이터의 후 처리



###### settings.py

scrapy의 설정



###### spiders

실제로 스크랩할 내용들을 작성하는 디렉토리



##### 3) 예제 : 페이지를 전부 스크랩

###### tutorial\items.py

```python
import scrapy

class TutorialItem(scrapy.Item):
    title = scrapy.Field()
    link = scrapy.Field()
    desc = scrapy.Field()
```



###### tutorial\spiders\dmoz_spider.py

```python
import scrapy

class DmozSpider(scrapy.Spider):
    name = "dmoz"
    allowed_domains = ["dmoztools.net"]

    start_urls = [
        "http://dmoztools.net/Computers/Programming/Languages/Python/Books/",
        "http://dmoztools.net/Computers/Programming/Languages/Python/Resources/"
    ]

    # 실제로 동작하는 부분
    def parse(self, response):
        filename = response.url.split("/")[-2]
        with open(filename, 'wb') as f:
            f.write(response.body)
```



###### scrapy 실행

```bash
cd tutorial
scrapy crawl dmoz
```



##### 4) 예제 : 페이지 내부에서 특정 데이터 가져오기

- 페이지 요소 검사 : XPath
  - //*[@id="site-list-content"]/div[1]/div[3]/a**
  - **//*[@id="site-list-content"]/div[1]/div[3]/a/div
  - //*[@id="site-list-content"]/div[2]/div[3]/div





###### scrapy shell

```bash
# scrapy shell "url"
scrapy shell "http://dmoztools.net/Computers/Programming/Languages/Python/Books/"
```

```shell
>>> response.xpath('//title')
[<Selector xpath='//title' data=u'<title>DMOZ - Computers: Programming: La'>]

```

- `//` : html 내부의 title을 모두 다 가져와라



```shell
>>> response.xpath('//title').extract()
[u'<title>DMOZ - Computers: Programming: Languages: Python: Books</title>']
```

- `.extract()` : data만 추출





```shell
>>> response.xpath('//title/text()')
[<Selector xpath='//title/text()' data=u'DMOZ - Computers: Programming: Languages'>]
>>> response.xpath('//title/text()').extract()
[u'DMOZ - Computers: Programming: Languages: Python: Books']
```

- `//title/text()` : tag 포함하지 않고, 내용만





```shell
>>> response.xpath('//title/text()').re('(\w+):')
[u'Computers', u'Programming', u'Languages', u'Python']
```

- 정규 표현식을 가져와서 word 단위로 바꿔라



###### tutorial\spiders\dmoz_spider.py : 파일로 저장하는 것이 아닌 title, link, description 출력

```python
import scrapy

class DmozSpider(scrapy.Spider):
    name = "dmoz"
    allowed_domains = ["dmoztools.net"]

    start_urls = [
        "http://dmoztools.net/Computers/Programming/Languages/Python/Books/",
        "http://dmoztools.net/Computers/Programming/Languages/Python/Resources/"
    ]

    # action
    def parse(self, response):

        for sel in response.xpath('//*[@id="site-list-content"]/div'):
            # item = TutorialItem()

            title = sel.xpath('div[3]/a/div/text()').extract()
            link = sel.xpath('div[3]/a/@href').extract()
            desc = sel.xpath('div[3]/div/text()').extract()

            print(title, link, desc)
            print()

```

